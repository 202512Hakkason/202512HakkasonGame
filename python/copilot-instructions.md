# copilot-instructions.md

# Github Copilot への指示書

## 1. プロジェクト概要
このプロジェクトは、Webカメラで捉えた人間の動き（骨格）を利用して音を奏でるインタラクティブなゲームを開発するためのものです。
システムは以下の2つの主要コンポーネントで構成されています：
1. **Python (Sensor & Logic):** 映像取得、骨格推定、キーポイント座標の抽出、Unityへのデータ送信を担当。
2. **Unity (View & Audio):** Pythonから送られたデータに基づき、音の再生やゲーム画面の描画を担当。

## 2. Pythonプロジェクトの役割と要件
Python側は「センサー兼ロジック」として機能します。以下のフローを実装します。
- **入力:** OpenCVを使用してWebカメラから映像を取得。
- **処理:** MediaPipe Poseを使用してリアルタイムで骨格推定を行う。特に「手首（Wrist）」のY座標を取得し、画面の高さに応じた音階（離散値）に変換するロジックを含む。
- **出力:** 抽出したデータ（音階インデックスや座標）をUDP通信（Socket）でローカルのUnityアプリケーションへ送信する。

### フォルダ構成
以下の構成を前提としてコードを提案してください。
- `main.py`: エントリーポイント。各モジュールの統括。
- `config.py`: 定数管理（IPアドレス、ポート番号、カメラID、閾値など）。
- `pose_detector.py`: MediaPipeのラッパークラス。画像の入力からキーポイント座標の抽出までを担当。
- `udp_sender.py`: UDP通信のラッパークラス。データの送信処理を担当。
- `sound_translater.py`: 手首のY座標を音階インデックスに変換するロジックを担当。

## 3. コーディング規約 (Coding Guidelines)

### 単一責任の原則 (Single Responsibility Principle)
- クラスや関数は「一つのこと」だけを行うように設計してください。
- 例: `pose_detector.py` は「推定」と「座標取得」に集中し、通信処理は含めないでください。
- 例: `udp_sender.py` は「送信」に集中し、ゲームのロジック（音階計算など）を含めないでください。

### 可読性の重視 (Readability)
- **変数名:** 明確で意味のある英語の名前を使用してください（例: `x` ではなく `wrist_x_position`）。
- **型ヒント (Type Hinting):** 関数の引数と戻り値には必ず型ヒントを記述してください（例: `def send(self, message: str) -> None:`）。
- **コメント:** 複雑なロジックには簡潔な説明をつけてください。

### 適切なモジュール化 (Modularization)
- `main.py` にすべての処理を書かないでください。
- 設定値（マジックナンバー）は `config.py` に集約し、ハードコーディングを避けてください。

## 4. 使用ライブラリ
- `opencv-python`
- `mediapipe`
- `socket` (標準ライブラリ)

## 5. チャット規約
- チャットへの返答は日本語で行ってください。

## 6. Unityとの通信仕様 (参考)
- プロトコル: UDP
- IP: 127.0.0.1 (localhost)
- Port: configで指定 (例: 50005)
- データ形式: 文字列（例: "NOTE,3" や "CYMBAL,ON" など、単純なテキスト形式を推奨）

